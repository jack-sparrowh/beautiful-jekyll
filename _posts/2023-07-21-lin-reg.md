---
layout: post
title: IN PROGRESS Prediction Error of Statistical Linear Regression
subtitle: It's more than just a line
tags: [statistics, probability, random vectors, linear regression, expected value, prediction error]
---

## 1. Few words about myself
I come from a background of Chemical Engineering, so for a significant part of my life, linear regression was the reglinp function in Excel – easy to set up and use. This is what I relied on during my university years. I always looked down on linear regression, thinking it was too simple and not worthy of anyone's time. I never knew how wrong I was. Over the past two years of self-study, I grew to appreciate how beautiful and, most importantly, how complex linear regression is. It was almost a spiritual experience, which humbled me to the core, to uncover completely new depths of this 'simple' model, and it is all thanks to statistics. For this reason, I recognize two types of linear regression: the one I used and neglected, and the statistical one. Thus, the title of this blog.

## 2. Notation
In a typical fashion we let scalar values be denoted as lowecase letters $$x$$. Any arbitrary vetor is denoted by bold lowecase letters $$\mathbf{x}$$ and comes form $$\mathbb{R}^{n}$$. Any arbitrary matrix is denoted by bold uppercase letters $$\mathbf{X}$$, and matrices come from $$\mathbb{R}^{m \times n}$$ unless stated otherwise. Random variables are denoted as uprecase letters $$X$$, random vectors are denoted as $$\mathbb{X}$$, and random matrices are denoted as $$\mathcal{X}$$. Symbols with hat ( $$\hat{.}$$ \) are estimators or estimates. There are many ways to denote PDFs, here we will use the notation $$f_{X}(x)$$. What about PMFs? We change them to PDFs using "delta-train" as $$f_{X}(x) = \sum_{k \in X(\Omega)} \mathcal{P} (X = k) \delta(x - k)$$ and we don't think about them any more. The $$l2$$-norm for arbitrary vector space $$V$$ is denoted as $$|| \cdot ||^{2}$$. Note here, that $$\mathcal{P}$$ is not a power set it is a probability. I'm usually using $$\mathbb{P}$$, but i decided not to for readability puproses. I think that it is all we need. When we will use something not stated here, it will be clearly explained. 

### 2.1. Shape of $$\textbf{X}$$
So, in **2.** we have defined $$\mathbf{X}$$ to be a $$m \times n$$ matrix of data points. I'm always treating rows to be observations and columns to be features. For example, if $$\mathbf{X}$$ describes a medical data, rows would be patients and columns would be different parameters, like height, age, blood pressure etc. I know that some books and courses take different approach and consider the dataset to be $$\mathbf{X}^{T}$$. So, if $$\mathbf{x}_{i}$$ is an $$i$$th observation in the dataset, we define the dataset as:
{: style="text-align: justify"}

$$
\begin{align}
 \mathbf{X} = 
 \begin{pmatrix} 
 \mathbf{x}_{1}^{T} \\
 \vdots \\
 \mathbf{x}_{n}^{T}  
 \end{pmatrix}
 \in \mathbb{R}^{m \times n}
\end{align}
$$

## 3. Complaining about the expected value
There are handful of examples where authors use the notation for expected value i really love [… references…], which is, to write in subscript with respect to what random variable we are taking the expectation. So, instead of $$\mathcal{E}[g(X, Y)]$$ we would write $$\mathcal{E}_{X, Y}[g(X, Y)]$$. I cannot understand why isn't it much more popular in the field, especially in introductory books or when we are dealing with more than just one random variable under the expectation sign. When using this notation, one cannot just skip steps, or omit the assumtions and proceed further, because it is immediately obvious. The expected value is a function, just like any other, the only difference (compared to standard calculus classes) is that it utilizes the Lebesgue integral, since for any probability space {$$\Omega$$, $$\mathcal{F}$$, $$\mathcal{P}$$} and some arbitrary random variable $$X: \Omega \to \mathbb{R}$$, we define the expected value as:

$$
\begin{align}
 \mathcal{E}_{X} \left[ X \right] = \int_{\Omega} X d \mathcal{P} \Rightarrow 
 \int_{\mathbb{R}} x f_{X}(x) dx
\end{align}
$$

where $$\mathcal{dP}$$ is the Lebesgue measure. The defining equation is more or less abstract, but it implies the form we have all seen before. The most important thing is that $$X$$ in the subscript of $$\mathcal{E}$$ tells us that the integration is carried out using $$f_{X}(x)dx$$. So, here is a little task for you. If $$\mathbb{Y}$$ is some arbitrary random vector, $$\mathcal{X}$$ is some arbitrary random matrix, with joint probability $$\mathcal{P}(\mathbb{Y}, \mathcal{X})$$, $$\mathcal{D}$$ is the random dataset sample and  $$\hat{\beta}(\mathcal{D})$$ is an estimator for model parameter. Try to write  expected value below in the integral form.

$$
\begin{align}
 \mathcal{E} \left[|| \mathbb{Y} - f_{\hat{\beta}(\mathcal{D})} (\mathcal{X}) || ^ {2} \right]
\end{align}
$$

One might say that the integral form depends on the context of the discussion, of course, but as you will see it is very easy to solve it with whatever random variables you want, for example by ommiting the fact that $$\hat{\beta}(\mathcal{D})$$ depends on elements of $$\mathcal{D}$$, and consider just some of those elements. If you are deep into statistics you can understand what's going on, but for people starting in statistics or trying to learn new things it can take a lot of time to decipher what is happening from one step to another. This is especially frustrating as the notation from one book to another, from one article to another is not consistent. Thus, I want to be as clear as possible in this blog, and i'm going to be straight honest with you right now, 

<strong>i'm not 100% sure about some of the results, as i have failed miserably to find any supporting texts on this topic with clear and consistent solution, please keep that in mind. My derivations will be clearly indicated. All the other results will be marked by an appropriate sorce</strong>. 

So, you might ask "What is the purpose of this blog then?", and to be honest i think that the questions asked here are very interesting when it comes down to solving (or trying to solve) the statistical linear regression.

## 4. Getting up to speed with (linear) models
Minimization of some empirical risk function, by finding the right hypothesis(which is a fancy word for model) is the main goal of machine learning. If we let average value of $$l2$$-norm to be our empirical risk function and linear regression to be the hypothesis, then by assuming some characteristics of added error it is fairly easy to find not only the vector parameter for linear model, but other interesting relations. 

So, in short if we let $$R_{emp}(f_{\hat{\beta}}) = \frac{1}{N} \vert \vert \mathbf{Y} - f_{\hat{\beta}}(\mathbf{X}) \vert \vert^{2}$$, and $$f_{\hat{\beta}}(\mathbf{X}) = \mathbf{X} \hat{\beta}$$, then the solution for the paramtere vector is exactly the OLS solution. The OLS solution should be known to everyone interested in statistics. But, just to remind you, if $$\mathbf{y} \in \mathbb{R}^{m}$$ and $$\mathbf{X} \in \mathbb{R}^{m \times n}$$, the OLS estimator is:

$$
\begin{align}
 \hat{\beta}_{OLS} = \left( \mathbf{X}^{T} \mathbf{X} \right)^{-1} \mathbf{X}^{T} \mathbf{y} \in \mathbb{R}^{n}
\end{align}
$$

If you have no idea where did it come from, at the end I'm providing two ways of deriving this result, one using matrix calculus and the other one using linear algebra (no calculus needed!).

### 4.1. General assumtion about the true relation
Our main assumption is that there exist a true relation between the target and vector of observations with added normally distributed error (it doesn't have to be normal, but for simplicity we let it be that way):

$$
\begin{align}
 y = f(\mathbf{x}) + e, \ e \sim N(0, \sigma^{2})
\end{align}
$$

This is the simplest, and I would say the most fundamental assumption in machine learning. We state that there exists a relation that connects the target variable with measured variables, but we know that we cannot measure ALL possible variables, and that the measurement precision is finite. Thus, we accept the fact that a random error is going to be added to the true value, which gives rise to the joint probability distribution over the possible outcomes space $$\Omega_{Y} \times \Omega_{\mathbb{X}}$$, denoted as $$\mathcal{P} (Y, \mathbb{X})$$ and later referred to as $$f_{Y, \mathbb{X}}(y, \mathbf{x})$$.

### 4.2. What about error in $$\mathbf{X}$$?
Every day, I carry out the same series of reactions, each denoted as reaction $$i$$, where I collect data about the yield $$y_{i}$$ of the main product (targets). I record various parameters, such as the sampling time, temperature, masses of substrates added to the reactor, and more. All these parameters together form my observation vector $$\mathbf{x}_{i}$$. However, it's important to note that each time I perform the reaction, I precisely control and determine the values of $$\mathbf{x}_{i}$$ by consciously selecting the parameters. Therefore, there is no inherent randomness associated with any of the components of $$\mathbf{x}_{i}$$! This implies that the distribution of any chosen parameter set collapses to a Dirac delta distribution $$\delta(\mathbf{x} - \mathbf{x}_{i})$$.

Nonetheless, a challenge arises when I observe that over time, not all values within each $$\mathbf{x}_{i}$$ match those originally intended in the design matrix that I prepared during the initial planning phase. In certain reactions, certain values deviate slightly from the intended values. For example, the temperature might not be exactly $$160 \ ^{\circ} \text{C}$$ after $$10 \ \text{minutes}$$, or a sample might be taken after $$32 \ \text{minutes}$$ instead of the planned $$30 \ \text{minutes}$$. This discrepancy introduces an element of randomness into the process. The design matrix itself incorporates randomness, implying that each parameter is subject to an underlying error term, the specifics of which remain unknown. Thus, an inherent randomness permeates various aspects of our lives that we cannot fully eliminate. 

Above, the discussion highlights two cases to consider for the data matrix: random and nonrandom. For our focus, we will concentrate solely on the random case. The solutions for nonrandom situations are fundamentally the same as those for the random case, which is more general in nature and covers a broader range of scenarios.

There are two areas we are interested in. The first one is at the center of what machine learning is all about, it is prediction error (test error) and train error. Mathematically they are denoted as:

$$
\begin{align}
 \text{Train error: } \mathcal{E}_{\mathbb{Y}, \mathcal{X}, \mathcal{D}} 
 \left[ \vert \vert \mathbb{Y} - f_{\hat{\beta}(\mathcal{D})}(\mathcal{X}) \vert \vert^{2}  \right]
\end{align}
$$ 

$$
\begin{align}
 \text{Test error: } \mathcal{E}_{\mathbb{Y'}, \mathcal{X'}, \mathcal{D}} 
 \left[ \vert \vert \mathbb{Y'} - f_{\hat{\beta}(\mathcal{D})}(\mathcal{X'}) \vert \vert^{2}  \right]
\end{align}
$$

$$
\begin{align}
\end{align}
$$
